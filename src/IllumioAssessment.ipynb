{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b26dab-b5e2-446a-9776-e42553e1b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "#Making use of default libraries only\n",
    "\n",
    "class LogTagger:\n",
    "    def __init__(self, lookup_file):\n",
    "        self.lookup = self._read_lookup_table(lookup_file)\n",
    "\n",
    "    def _read_lookup_table(self, filename):\n",
    "        \n",
    "        ##Reading lookup table from CSV file\n",
    "        lookup = {}\n",
    "        try:\n",
    "            with open(filename, mode='r', newline='') as file:\n",
    "                reader = csv.DictReader(file)\n",
    "                for row in reader:\n",
    "                    key = (row['dstport'].strip(), row['protocol'].strip().lower()) ##Lower casing to work for case insensitivity\n",
    "                    lookup[key] = row['tag'].strip() ##using tag as the key\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File {filename} not found.\")\n",
    "            return {}\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "            return {}\n",
    "        return lookup\n",
    "\n",
    "    def _generate_output(self, output_filename, tag_counts, port_protocol_counts):\n",
    "        ##Tag counts and Port/Protocol combination counts\n",
    "        ##generating output file\n",
    "        try:\n",
    "            with open(output_filename + '_tag_counts.csv', 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['Tag', 'Count'])\n",
    "                ##We sort using the custom key set provided by lambda function\n",
    "                for tag, count in sorted(tag_counts.items(), key=lambda x: (x[1], x[0])): ##x[1] will sort ascending order of count. x[0] will sort tag based on alphabetical order in case of matching counts.\n",
    "                    writer.writerow([tag, count])\n",
    "\n",
    "            with open(output_filename + '_port_protocol_counts.csv', 'w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(['Port', 'Protocol', 'Count'])\n",
    "                for key, count in sorted(port_protocol_counts.items(), key=lambda x: (int(x[0][0]), x[1])): ##x[0][0] will ensure sorting is done numerically according to port number for ease of use\n",
    "                    writer.writerow([key[0], key[1], count])\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating output files: {e}\")\n",
    "\n",
    "    def apply_tags_to_logs(self, logs_filename, output_filename):\n",
    "        #Applying tags to log entries based on dstport and protocol\n",
    "        \n",
    "        tag_counts = defaultdict(int)\n",
    "        port_protocol_counts = defaultdict(int)\n",
    "\n",
    "        try:\n",
    "            with open(logs_filename, 'r', newline='') as infile, open(output_filename + '.csv', 'w', newline='') as outfile:\n",
    "                #This order is based on the AWS Flow Log Record provided in the mail. Assuming the same order is followed for the sample logs. \n",
    "                fieldnames = [\n",
    "                    'Version', 'AccountID', 'InterfaceID', 'SrcAddr', 'DstAddr', \n",
    "                    'SrcPort', 'DstPort', 'Protocol', 'Packets', 'Bytes', \n",
    "                    'StartTime', 'EndTime', 'Action', 'LogStatus', 'Tag'\n",
    "                ]\n",
    "                reader = csv.reader(infile, delimiter=' ')\n",
    "                writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "\n",
    "                for row in reader:\n",
    "                    log_entry = {fn: val for fn, val in zip(fieldnames[:-1], row)}\n",
    "                    #Assuming the port numbers are standard so 6 for TCP and 17 for UDP and 1 for ICMP\n",
    "                    protocol = {'6': 'tcp', '17': 'udp', '1': 'icmp'}.get(log_entry['Protocol'], 'unknown')\n",
    "                    key = (log_entry['DstPort'], protocol)\n",
    "                    #Unknown ports are marked as Untagged\n",
    "                    tag = self.lookup.get(key, 'Untagged')\n",
    "                    log_entry['Tag'] = tag\n",
    "                    writer.writerow(log_entry)\n",
    "\n",
    "                    tag_counts[tag] += 1\n",
    "                    port_protocol_counts[key] += 1\n",
    "\n",
    "            self._generate_output(output_filename, tag_counts, port_protocol_counts)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File {logs_filename} not found.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing logs: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ##Using Lookup and sampleFlowLogs as plain txt files as mentioned in the requirements. We are then converting them to CSV to output it in a structured way. \n",
    "    log_tagger = LogTagger('lookup.txt')\n",
    "    log_tagger.apply_tags_to_logs('sampleFlowLogs.txt', 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d655333-a7a9-41ca-89b8-94067e4c6cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
